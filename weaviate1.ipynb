{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSL\n",
    "# cd /mnt/c/Users/rs659/Desktop/mmsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n mmsearchenv python=3.9\n",
    "# conda activate mmsearchenv\n",
    "# conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "# pip install -r requirements.txt\n",
    "# docker-compose up -d\n",
    "\n",
    "# https://anaconda.org/conda-forge/docker-compose\n",
    "\n",
    "\n",
    "# docker rm -f $(docker ps -aq)\n",
    "\n",
    "\n",
    "# conda install -c conda-forge poppler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.nvidia.com/cuda-12-2-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/weaviate-tutorials/DEMO-multimodal-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "for f in Path(\"data/podcasts\").glob(\"*.json\"):  # assuming podcast data is in JSON files\n",
    "    # podcast_data = json.loads(f.read_text())\n",
    "    with open(f, 'r', encoding='utf-8') as file:\n",
    "        podcast_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(podcast_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_props = {\n",
    "#     \"title\": podcast_data[\"title\"],\n",
    "#     \"transcript\": podcast_data[\"transcript\"],\n",
    "#     \"description\": podcast_data[\"description\"],\n",
    "#     \"titleimage\": base64.b64encode(Path(podcast_data[\"titleimage\"]).read_bytes()).decode(),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import generate_uuid5\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "data_objs = list()\n",
    "podcast_dir = Path(\"data/podcasts\")\n",
    "for f in podcast_dir.glob(\"*.json\"):  # assuming podcast data is in JSON files\n",
    "    # podcast_data = json.loads(f.read_text())\n",
    "    with open(f, 'r', encoding='utf-8') as file:\n",
    "        podcast_data = json.load(file)\n",
    "    for podcast in podcast_data:\n",
    "        data_props = {\n",
    "            \"title\": podcast[\"title\"],\n",
    "            \"transcript\": podcast[\"transcript\"],\n",
    "            # \"description\": podcast[\"description\"],\n",
    "            # \"titleimage\": base64.b64encode(Path(podcast[\"titleimage\"]).read_bytes()).decode(),\n",
    "        }\n",
    "        data_obj = wvc.data.DataObject(\n",
    "            properties=data_props, uuid=generate_uuid5(f.name)\n",
    "        )\n",
    "        data_objs.append(data_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.util import generate_uuid5\n",
    "from weaviate import WeaviateClient\n",
    "from weaviate.collections.classes.batch import BatchObjectReturn\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "\n",
    "def connect() -> WeaviateClient:\n",
    "    return weaviate.connect_to_local()\n",
    "\n",
    "client = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mm_coll = client.collections.get('WineReviews') #some_objects = client.data_object.get()\n",
    "# print(json.dumps(mm_coll))\n",
    "\n",
    "# response = mm_coll.query.near_text(\n",
    "#         query=\"\",\n",
    "#         limit=2\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_coll = client.collections.get('WineReviews')\n",
    "\n",
    "response = mm_coll.aggregate.over_all(total_count=True)\n",
    "print(f\"Object count: {response.total_count}\")\n",
    "\n",
    "for q in [\"lions\"]:\n",
    "    response = mm_coll.query.near_text(q, limit=3)\n",
    "    print(f\"\\n{'*'*10} \\t Query: \\t {'*'*10}\\n\")\n",
    "    print(f\"\\t\\t {q} \\n\")\n",
    "    print(f\"{'*'*10} \\t RESULTS: \\t {'*'*10}\\n\")\n",
    "    for r in response.objects:\n",
    "        # print(r)\n",
    "        print(r.properties[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "elements = partition_pdf(filename=\"data/pdf/paper01.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import textwrap\n",
    "\n",
    "# narrative_texts = [elem for elem in elements if elem.category == \"NarrativeText\"]\n",
    "\n",
    "# for index, elem in enumerate(narrative_texts[:5]):\n",
    "#     print(f\"Narrative text {index + 1}:\")\n",
    "#     print(\"\\n\".join(textwrap.wrap(elem.text, width=70)))\n",
    "#     print(\"\\n\" + \"-\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_collection_pdfs(client: WeaviateClient, collection_name: str = 'pdfs') -> bool:\n",
    "\n",
    "    # Creating a new collection with the defined schema\n",
    "    client.collections.create(\n",
    "        name=collection_name,\n",
    "        properties=[\n",
    "            wvc.Property(\n",
    "                name=\"source\",\n",
    "                data_type=wvc.DataType.TEXT,\n",
    "            ),\n",
    "            wvc.Property(\n",
    "                name=\"abstract\",\n",
    "                data_type=wvc.DataType.TEXT,\n",
    "            )\n",
    "        ],\n",
    "        vectorizer_config=wvc.config.Configure.Vectorizer.multi2vec_bind(\n",
    "            text_fields=[wvc.config.Multi2VecField(name='title', weight=0.95)],\n",
    "            vectorize_collection_name=False )\n",
    "    )\n",
    "\n",
    "client.collections.delete('pdf')\n",
    "define_collection_pdfs(client,'pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class AbstractExtractor:\n",
    "    def __init__(self):\n",
    "        self.current_section = None  # Keep track of the current section being processed\n",
    "        self.have_extracted_abstract = (\n",
    "            False  # Keep track of whether the abstract has been extracted\n",
    "        )\n",
    "        self.in_abstract_section = (\n",
    "            False  # Keep track of whether we're inside the Abstract section\n",
    "        )\n",
    "        self.texts = []  # Keep track of the extracted abstract text\n",
    "\n",
    "    def process(self, element):\n",
    "        if element.category == \"Title\":\n",
    "            self.set_section(element.text)\n",
    "\n",
    "            if self.current_section == \"Abstract\":\n",
    "                self.in_abstract_section = True\n",
    "                return True\n",
    "\n",
    "            if self.in_abstract_section:\n",
    "                return False\n",
    "\n",
    "        if self.in_abstract_section and element.category == \"NarrativeText\":\n",
    "            self.consume_abstract_text(element.text)\n",
    "            return True\n",
    "\n",
    "        return True\n",
    "\n",
    "    def set_section(self, text):\n",
    "        self.current_section = text\n",
    "        logging.info(f\"Current section: {self.current_section}\")\n",
    "\n",
    "    def consume_abstract_text(self, text):\n",
    "        logging.info(f\"Abstract part extracted: {text}\")\n",
    "        self.texts.append(text)\n",
    "\n",
    "    def consume_elements(self, elements):\n",
    "        for element in elements:\n",
    "            should_continue = self.process(element)\n",
    "\n",
    "            if not should_continue:\n",
    "                self.have_extracted_abstract = True\n",
    "                break\n",
    "\n",
    "        if not self.have_extracted_abstract:\n",
    "            logging.warning(\"No abstract found in the given list of objects.\")\n",
    "\n",
    "    def abstract(self):\n",
    "        return \"\\n\".join(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/pdf/\"\n",
    "\n",
    "data_objects = []\n",
    "\n",
    "for path in Path(data_folder).iterdir():\n",
    "    if path.suffix != \".pdf\":\n",
    "        continue\n",
    "\n",
    "    # print(f\"Processing {path.name}...\")\n",
    "\n",
    "    elements = partition_pdf(filename=path)\n",
    "\n",
    "    abstract_extractor = AbstractExtractor()\n",
    "    abstract_extractor.consume_elements(elements)\n",
    "\n",
    "    data_object = {\"source\": path.name, \"abstract\": abstract_extractor.abstract()}\n",
    "\n",
    "    data_objects.append(data_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchObjectReturn(all_responses=[UUID('ecd88190-bd63-49c8-983a-c8962f79dd2f'), UUID('299eea7c-f816-46c8-8589-bfc82497e23f')], elapsed_seconds=0.002997875213623047, errors={}, uuids={0: UUID('ecd88190-bd63-49c8-983a-c8962f79dd2f'), 1: UUID('299eea7c-f816-46c8-8589-bfc82497e23f')}, has_errors=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client.batch.configure(batch_size=100)  # Configure batch\n",
    "# with client.batch as batch:\n",
    "#     for data_object in data_objects:\n",
    "#         batch.add_data_object(data_object, \"Document\")\n",
    "\n",
    "pdf_collection = client.collections.get('pdf')\n",
    "\n",
    "pdf_collection.data.insert_many(data_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Purchasing a home is one of the largest investments most people make. House price prediction allows indi- viduals to be informed about their asset wealth. Trans- parent pricing on homes allows for a more efficient mar- ket and economy. We report the performance of ma- chine learning models trained with structured tabular representations and unstructured text descriptions. We collected a dataset of 200 descriptions of houses which include meta-information, as well as text descriptions. We test logistic regression and multi-layer perceptron (MLP) classifiers on dividing these houses into binary buckets based on fixed price thresholds. We present an exploration into strategies to represent unstructured text descriptions of houses as inputs for machine learning models. This includes a comparison of term frequency- inverse document frequency (TF-IDF), bag-of-words (BoW), and zero-shot inference with large language models. We find the best predictive performance with TF-IDF representations of house descriptions. Readers will gain an understanding of how to use machine learn- ing models optimized with structured and unstructured text data to predict house prices.\\nIntroduction Predicting house prices is crucial for buyers, sellers, and the economy as a whole. Real estate prices fluctuate based on multiple factors such as macroeconomic indicators and local economic activity. Agents in the real estate market al- ter their decisions based on their information about the state of the economy. The notion of information asymmetry states that varying information from the buyer or seller could lead to market failure. Spence demonstrated that sellers could signal to buyers in order to avoid adverse selection (Spence 2002). Signaling is the action of one agent with more in- formation conveying insights to the other party. Cypher et al. studied the impact of price signaling from brokers in commercial real estate transactions (Cypher et al. 2017). Their study found that if the price is above the market rate, then pricing is dependent on the strength of the signal. We explore signaling through transparent pricing with accessi- ble predictions from machine learning models. Transparent pricing would lead businesses or individuals to be more con-\\nfident and make decisions quicker, leading to a more effi- cient market. Forecasting house prices is a tool for trans- parent pricing that we explore with machine learning tech- niques.\\nWe experiment with predicting house prices with data- driven techniques. The key to data-driven predictive analyt- ics is the feature representation of houses in the dataset. We collect a dataset of prices, meta-information about houses, and written descriptions. Meta-information includes features about houses such as the number of bedrooms, bathrooms, and square feet. Written descriptions are an emerging data source, with excitement fueled by recent advances in deep learning for natural language processing. A written house description is an open-ended report typically written by real estate brokers to describe a particular house.\\nOur experiments present data-driven modeling of 200 houses featurized by meta-information and written descrip- tions. We convert the written descriptions to numeric inputs through the term frequency-inverse document frequency (TF-IDF) algorithm, which is described in further detail in the Related Work section of our report. We begin by pre- senting the performance difference of a logistic regression model mapping either tabular descriptions or TF-IDF vec- tors to binary bins of house prices. The logistic regression model processing tabular data achieves 79.3% training ac- curacy and generalizes to 76.2% test accuracy. The logis- tic regression model with TF-IDF impetus achieves a 2.4% higher test accuracy at 78.6%, however, it has fit the training data very closely, achieving 100% training accuracy. This generalization gap between training and testing inspired our interest into deep learning architectures for TF-IDF repre- sentations of unstructured text data. We utilize a 3-layer non- linear MLP architecture and add dropout to control for over- fitting and limit the variance of the parametric function. We further compare TF-IDF representations of house descrip- tions to BoW representations. We additionally present the zero-shot inference of a 6-billion parameter publicly acces- sible language model to predict house prices.\\nIn summary, our contributions are as follows:\\nCopyright © 2022by the authors. All rights reserved.', 'source': 'paper02.pdf'}\n"
     ]
    }
   ],
   "source": [
    "response = pdf_collection.query.fetch_objects(\n",
    "    include_vector=True,\n",
    "    limit=1,\n",
    "    offset=1\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': 'Purchasing a home is one of the largest investments most people make. House price prediction allows indi- viduals to be informed about their asset wealth. Trans- parent pricing on homes allows for a more efficient mar- ket and economy. We report the performance of ma- chine learning models trained with structured tabular representations and unstructured text descriptions. We collected a dataset of 200 descriptions of houses which include meta-information, as well as text descriptions. We test logistic regression and multi-layer perceptron (MLP) classifiers on dividing these houses into binary buckets based on fixed price thresholds. We present an exploration into strategies to represent unstructured text descriptions of houses as inputs for machine learning models. This includes a comparison of term frequency- inverse document frequency (TF-IDF), bag-of-words (BoW), and zero-shot inference with large language models. We find the best predictive performance with TF-IDF representations of house descriptions. Readers will gain an understanding of how to use machine learn- ing models optimized with structured and unstructured text data to predict house prices.\\nIntroduction Predicting house prices is crucial for buyers, sellers, and the economy as a whole. Real estate prices fluctuate based on multiple factors such as macroeconomic indicators and local economic activity. Agents in the real estate market al- ter their decisions based on their information about the state of the economy. The notion of information asymmetry states that varying information from the buyer or seller could lead to market failure. Spence demonstrated that sellers could signal to buyers in order to avoid adverse selection (Spence 2002). Signaling is the action of one agent with more in- formation conveying insights to the other party. Cypher et al. studied the impact of price signaling from brokers in commercial real estate transactions (Cypher et al. 2017). Their study found that if the price is above the market rate, then pricing is dependent on the strength of the signal. We explore signaling through transparent pricing with accessi- ble predictions from machine learning models. Transparent pricing would lead businesses or individuals to be more con-\\nfident and make decisions quicker, leading to a more effi- cient market. Forecasting house prices is a tool for trans- parent pricing that we explore with machine learning tech- niques.\\nWe experiment with predicting house prices with data- driven techniques. The key to data-driven predictive analyt- ics is the feature representation of houses in the dataset. We collect a dataset of prices, meta-information about houses, and written descriptions. Meta-information includes features about houses such as the number of bedrooms, bathrooms, and square feet. Written descriptions are an emerging data source, with excitement fueled by recent advances in deep learning for natural language processing. A written house description is an open-ended report typically written by real estate brokers to describe a particular house.\\nOur experiments present data-driven modeling of 200 houses featurized by meta-information and written descrip- tions. We convert the written descriptions to numeric inputs through the term frequency-inverse document frequency (TF-IDF) algorithm, which is described in further detail in the Related Work section of our report. We begin by pre- senting the performance difference of a logistic regression model mapping either tabular descriptions or TF-IDF vec- tors to binary bins of house prices. The logistic regression model processing tabular data achieves 79.3% training ac- curacy and generalizes to 76.2% test accuracy. The logis- tic regression model with TF-IDF impetus achieves a 2.4% higher test accuracy at 78.6%, however, it has fit the training data very closely, achieving 100% training accuracy. This generalization gap between training and testing inspired our interest into deep learning architectures for TF-IDF repre- sentations of unstructured text data. We utilize a 3-layer non- linear MLP architecture and add dropout to control for over- fitting and limit the variance of the parametric function. We further compare TF-IDF representations of house descrip- tions to BoW representations. We additionally present the zero-shot inference of a 6-billion parameter publicly acces- sible language model to predict house prices.\\nIn summary, our contributions are as follows:\\nCopyright © 2022by the authors. All rights reserved.', 'source': 'paper02.pdf'}\n",
      "{'abstract': 'Purchasing a home is one of the largest investments most people make. House price prediction allows indi- viduals to be informed about their asset wealth. Trans- parent pricing on homes allows for a more efficient mar- ket and economy. We report the performance of ma- chine learning models trained with structured tabular representations and unstructured text descriptions. We collected a dataset of 200 descriptions of houses which include meta-information, as well as text descriptions. We test logistic regression and multi-layer perceptron (MLP) classifiers on dividing these houses into binary buckets based on fixed price thresholds. We present an exploration into strategies to represent unstructured text descriptions of houses as inputs for machine learning models. This includes a comparison of term frequency- inverse document frequency (TF-IDF), bag-of-words (BoW), and zero-shot inference with large language models. We find the best predictive performance with TF-IDF representations of house descriptions. Readers will gain an understanding of how to use machine learn- ing models optimized with structured and unstructured text data to predict house prices.\\nIntroduction Predicting house prices is crucial for buyers, sellers, and the economy as a whole. Real estate prices fluctuate based on multiple factors such as macroeconomic indicators and local economic activity. Agents in the real estate market al- ter their decisions based on their information about the state of the economy. The notion of information asymmetry states that varying information from the buyer or seller could lead to market failure. Spence demonstrated that sellers could signal to buyers in order to avoid adverse selection (Spence 2002). Signaling is the action of one agent with more in- formation conveying insights to the other party. Cypher et al. studied the impact of price signaling from brokers in commercial real estate transactions (Cypher et al. 2017). Their study found that if the price is above the market rate, then pricing is dependent on the strength of the signal. We explore signaling through transparent pricing with accessi- ble predictions from machine learning models. Transparent pricing would lead businesses or individuals to be more con-\\nfident and make decisions quicker, leading to a more effi- cient market. Forecasting house prices is a tool for trans- parent pricing that we explore with machine learning tech- niques.\\nWe experiment with predicting house prices with data- driven techniques. The key to data-driven predictive analyt- ics is the feature representation of houses in the dataset. We collect a dataset of prices, meta-information about houses, and written descriptions. Meta-information includes features about houses such as the number of bedrooms, bathrooms, and square feet. Written descriptions are an emerging data source, with excitement fueled by recent advances in deep learning for natural language processing. A written house description is an open-ended report typically written by real estate brokers to describe a particular house.\\nOur experiments present data-driven modeling of 200 houses featurized by meta-information and written descrip- tions. We convert the written descriptions to numeric inputs through the term frequency-inverse document frequency (TF-IDF) algorithm, which is described in further detail in the Related Work section of our report. We begin by pre- senting the performance difference of a logistic regression model mapping either tabular descriptions or TF-IDF vec- tors to binary bins of house prices. The logistic regression model processing tabular data achieves 79.3% training ac- curacy and generalizes to 76.2% test accuracy. The logis- tic regression model with TF-IDF impetus achieves a 2.4% higher test accuracy at 78.6%, however, it has fit the training data very closely, achieving 100% training accuracy. This generalization gap between training and testing inspired our interest into deep learning architectures for TF-IDF repre- sentations of unstructured text data. We utilize a 3-layer non- linear MLP architecture and add dropout to control for over- fitting and limit the variance of the parametric function. We further compare TF-IDF representations of house descrip- tions to BoW representations. We additionally present the zero-shot inference of a 6-billion parameter publicly acces- sible language model to predict house prices.\\nIn summary, our contributions are as follows:\\nCopyright © 2022by the authors. All rights reserved.', 'source': 'paper02.pdf'}\n"
     ]
    }
   ],
   "source": [
    "response = pdf_collection.query.bm25(\n",
    "     query=\"largest\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pdf_collection.query.hybrid(\n",
    "     query=\"some thing about ghar\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "# for o in response.objects:\n",
    "#     print(o.properties)\n",
    "\n",
    "\n",
    "type(response.objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
    "    # .with_near_text(nearText)\n",
    "    .with_limit(2)\n",
    "    .with_additional(['certainty'])\n",
    "    .do()\n",
    ")\n",
    "\n",
    "pdf_collection.query.near_text(\"some paper about housing prices\", limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
