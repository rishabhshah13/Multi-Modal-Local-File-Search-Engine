{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSL\n",
    "# cd /mnt/c/Users/rs659/Desktop/mmsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0de7e8eef9b483a8a6a96b20f1836b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rs659\\AppData\\Local\\anaconda3\\envs\\mmsearchenv\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rs659\\.cache\\huggingface\\hub\\models--TinyLlama--TinyLlama-1.1B-Chat-v1.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda021bdaea64efb999958b600dcd9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30771e2bed16471da47f8e07875f67e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/289M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rs659\\AppData\\Local\\anaconda3\\envs\\mmsearchenv\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rs659\\.cache\\huggingface\\hub\\models--HongxuanLi--TinyLLaMA-RS. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8b3cee0c7642fa818d4a476df48b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188d70f12a1c4a3984c32fdc62152205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3273098631ee4cd3b79005d209747eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23140e71321444791d7be9e98f8005c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "config = PeftConfig.from_pretrained(\"HongxuanLi/TinyLLaMA-RS\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "model = PeftModel.from_pretrained(model, \"HongxuanLi/TinyLLaMA-RS\")\n",
    "tokenizer = AutoTokenizer.from_pretrained( \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(ft_model, eval_tokenizer, query):\n",
    "    infer_prompt = f\"\"\"You are an expert at extracting useful information from user queries. I need you to extract meta information from the user's query.  The extraction reults contain 'year', 'month', 'day', 'file content', 'file type' information for file retriever to locate the file. The extracted information should exclusively contain key-value pairs. Additionally, please generate 5 synonyms for the extracted 'file content'. Below are 5 examples that meet these requirements:\n",
    "Example1\n",
    "### query: Project documentation from January 15, 2024, to February 20, 2024\n",
    "### information: {{'year': [2024, 2024], 'month': [1, 2], 'day': [15, 20], 'file content': ['Project Documentation', 'Project Files', 'Project Overview', 'Project Details', 'Project Progress Documentation'], 'file type': ['pdf', 'doc', 'docx']}}\n",
    "\n",
    "Example2\n",
    "### query: Find my photos from New York last summer\n",
    "### information: {{'year': [-1, -1], 'month': [6, 8], 'day': [0, 0], 'file content': ['Photo taken in New York', 'New York Image', 'New York Snapshot', 'New York Picture', 'New York Photograph'], 'file type': ['jpg', 'jpeg', 'png', 'heif', 'tiff']}}\n",
    "\n",
    "Example3\n",
    "### query: How is AI transforming healthcare diagnostics?\n",
    "### information: {{'year': [], 'month': [], 'day': [], 'file content': ['AI in Healthcare Diagnostics', 'Artificial Intelligence and Medical Imaging', 'Machine Learning for Early Detection', 'AI Applications in Healthcare', 'Innovations in AI-based Diagnostics'], 'file type': ['pdf', 'docx', 'pptx', 'mp4', 'mp3']}}\n",
    "\n",
    "Example4\n",
    "### query: Conference materials from the Global Tech Summit held from 2023/10/10 to 2023/10/12\n",
    "### information: {{'year': [2023, 2023], 'month': [10, 10], 'day': [10, 12], 'file content' : ['Global Tech Summit Materials', 'Tech Summit Presentations', 'Tech Conference Docs', 'Tech Summit Slides', 'Tech Summit Proceedings'], 'file type': ['pdf', 'pptx', 'doc', 'docx']}}\n",
    "\n",
    "Example5\n",
    "### query: The best ways to introduce coding to children\n",
    "### information: {{'year': [], 'month': [], 'day': [], 'file content': ['Coding for Kids', 'Children\\'s Programming Basics', 'Fun Coding Projects for Kids', 'Learning to Code Through Games', 'Introduction to Programming for Young Learners'], 'file type': ['pdf', 'docx', 'pptx', 'mp4']}}\n",
    "\n",
    "Example6\n",
    "### query: The latest annual reports of ABC Ltd\n",
    "### information: {{'year': [0, 0], 'month': [0, 0], 'day': [0, 0], 'file content': ['ABC Ltd. Annual Report', 'Yearly Financial Statement of ABC Ltd.', 'Annual Summary of ABC Ltd.', 'ABC Ltd. Year-End Report', 'ABC Ltd. Fiscal Year Report'], 'file type': ['pdf', 'xlsx', 'xls', 'docx', 'doc']}}\n",
    "\n",
    "Now, please extract meta information from this user query:\n",
    "### query: {query}\n",
    "### information: \"\"\"\n",
    "    model_input = eval_tokenizer(infer_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    prediction = extract_answer(prediction)\n",
    "\n",
    "    if len(prediction) == 0:\n",
    "        prediction = \" \"\n",
    "    else:\n",
    "        prediction = prediction[\"information\"]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n mmsearchenv python=3.9\n",
    "# conda activate mmsearchenv\n",
    "# conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "# pip install -r requirements.txt\n",
    "# docker-compose up -d\n",
    "\n",
    "# https://anaconda.org/conda-forge/docker-compose\n",
    "\n",
    "\n",
    "\n",
    "# docker rm -f $(docker ps -aq)\n",
    "\n",
    "\n",
    "# conda install -c conda-forge poppler\n",
    "\n",
    "\n",
    "# Windows\n",
    "# cd  C:\\Users\\rs659\\Desktop\\Multi-Modal-Local-File-Search-Engine\n",
    "# conda deactivate\n",
    "# conda activate mmsearchenv\n",
    "# docker-compose up -d\n",
    "# python add_data.py\n",
    "# streamlit run app.py\n",
    "\n",
    "\n",
    "\n",
    "# WSL\n",
    "# cd /mnt/c/Users/rs659/Desktop/Multi-Modal-Local-File-Search-Engine\n",
    "# conda activate mmsearchenv\n",
    "# docker-compose up -d\n",
    "# python add_data.py\n",
    "# streamlit run app.py\n",
    "\n",
    "\n",
    "# https://github.com/weaviate/weaviate-examples/blob/main/weaviate-transformers-newspublications/docker-compose-withgpu.yaml\n",
    "# https://www.pexels.com/search/videos/cat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata of PDF\n",
    "# Add progress to batch insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.nvidia.com/cuda-12-2-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/weaviate-tutorials/DEMO-multimodal-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "for f in Path(\"data/podcasts\").glob(\"*.json\"):  # assuming podcast data is in JSON files\n",
    "    # podcast_data = json.loads(f.read_text())\n",
    "    with open(f, 'r', encoding='utf-8') as file:\n",
    "        podcast_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(podcast_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_props = {\n",
    "#     \"title\": podcast_data[\"title\"],\n",
    "#     \"transcript\": podcast_data[\"transcript\"],\n",
    "#     \"description\": podcast_data[\"description\"],\n",
    "#     \"titleimage\": base64.b64encode(Path(podcast_data[\"titleimage\"]).read_bytes()).decode(),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PDF Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.util import generate_uuid5\n",
    "from weaviate import WeaviateClient\n",
    "from weaviate.collections.classes.batch import BatchObjectReturn\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from AbstractExtractor import AbstractExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_collection_pdfs(client: WeaviateClient, collection_name: str = 'pdfs') -> bool:\n",
    "\n",
    "    # Creating a new collection with the defined schema\n",
    "    client.collections.create(\n",
    "        name=collection_name,\n",
    "        properties=[\n",
    "            wvc.Property(\n",
    "                name=\"filename\",\n",
    "                data_type=wvc.DataType.TEXT,\n",
    "            ),\n",
    "            wvc.Property(\n",
    "                name=\"abstract\",\n",
    "                data_type=wvc.DataType.TEXT,\n",
    "            ),\n",
    "            wvc.Property(\n",
    "                name=\"pages\",\n",
    "                # data_type=wvc.DataType.OBJECT_ARRAY,\n",
    "                data_type=wvc.DataType.TEXT_ARRAY,\n",
    "            )\n",
    "        ],\n",
    "        vectorizer_config=wvc.config.Configure.Vectorizer.multi2vec_bind(\n",
    "            text_fields=[wvc.config.Multi2VecField(name='filename', weight=0.50),\n",
    "                         wvc.config.Multi2VecField(name='abstract', weight=0.50)],\n",
    "            vectorize_collection_name=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local()\n",
    "client.collections.delete('pdf')\n",
    "\n",
    "define_collection_pdfs(client,'pdf')\n",
    "# import_data_pdf(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/pdf/\"\n",
    "\n",
    "data_objects = []\n",
    "\n",
    "for path in Path(data_folder).iterdir():\n",
    "    if path.suffix != \".pdf\":\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing {path.name}...\")\n",
    "\n",
    "    elements = partition_pdf(filename=path)\n",
    "    break\n",
    "    # abstract_extractor = AbstractExtractor()\n",
    "    # abstract_extractor.consume_elements(elements)\n",
    "\n",
    "    # data_object = {\"filename\": path.name, \"abstract\": abstract_extractor.abstract()[:50], \"pages\":[data.text for data in elements]}\n",
    "\n",
    "    # data_objects.append(data_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_collections.PDF import define_collection_pdfs, import_data_pdf\n",
    "from pathlib import Path\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import streamlit as st\n",
    "import base64\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from AbstractExtractor import AbstractExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_collection = client.collections.get('pdf')\n",
    "\n",
    "# pdf_collection.data.insert_many(data_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "jeopardy = client.collections.get(\"pdf\")\n",
    "response = jeopardy.query.bm25(\n",
    "    query=\"car safety is required\",\n",
    "    query_properties=[\"pages\"],\n",
    "    return_metadata=MetadataQuery(score=True),\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = client.collections.get(\"pdf\")\n",
    "response = jeopardy.query.hybrid(\n",
    "    query=\"car safety is required\",\n",
    "    alpha=0.5,\n",
    "    return_metadata=MetadataQuery(score=True, explain_score=True),\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pdf_collection.query.fetch_objects(\n",
    "    include_vector=True,\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pdf_collection.query.bm25(\n",
    "     query=\"price\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pdf_collection.query.hybrid(\n",
    "     query=\"car\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import streamlit as st\n",
    "import base64\n",
    "# from add_data import COLLECTION_NAME\n",
    "\n",
    "client = weaviate.connect_to_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_collection = client.collections.get('pdf')\n",
    "\n",
    "response = pdf_collection.aggregate.over_all(total_count=True)\n",
    "print(f\"Object count in the Database: {response.total_count}\")\n",
    "\n",
    "for q in [\"pdf\"]:\n",
    "    response = pdf_collection.query.bm25(\n",
    "            q, \n",
    "            limit=12,\n",
    "            include_vector=False,\n",
    "            # distance=0.5,\n",
    "            return_properties=['filename']\n",
    "            )\n",
    "\n",
    "print(response)\n",
    "print(len(response.objects))\n",
    "\n",
    "# big_reponse_list = []\n",
    "# big_reponse_list.append(response.objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = pdf_collection.aggregate.over_all(total_count=True)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
